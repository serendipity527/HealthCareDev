server:
  port: 8080

spring:
  application:
    name: websocket-chat

# LangChain4j AI 配置
langchain4j:
  open-ai:
    chat-model:
      # API密钥（必填）
      # 支持 OpenAI、DeepSeek、阿里云等兼容OpenAI API的服务
      api-key: ${AI_API_KEY:sk-43070f4cd1074965a93a03d6d5333cd8}
      
      # API基础URL（可选，默认为OpenAI官方地址）
      # OpenAI 官方: https://api.openai.com/v1
      # DeepSeek: https://api.deepseek.com
      # 阿里云: https://dashscope.aliyuncs.com/compatible-mode/v1
      # Ollama本地: http://localhost:11434/v1
      base-url: ${AI_BASE_URL:https://dashscope.aliyuncs.com/compatible-mode/v1}
      
      # 模型名称
      # OpenAI: gpt-3.5-turbo, gpt-4, gpt-4-turbo
      # DeepSeek: deepseek-chat
      # 阿里云: qwen-plus, qwen-turbo
      # Ollama: llama2, mistral 等
      model-name: ${AI_MODEL_NAME:qwen3-max}
      
      # 温度参数（0.0-2.0，值越大回复越随机）
      temperature: 0.7
      
      # 请求超时时间（秒）
#      timeout: 60
      
      # 最大token数
      max-tokens: 2000


# 日志配置
logging:
  level:
    com.yihu.agent: DEBUG
    dev.langchain4j: DEBUG
